import cv2
import mediapipe as mp
import time


class FaceDetect:
    def __init__(self, min_detection_confidence=0.5, model_selection=0):
        self.min_detection_confidence = min_detection_confidence
        self.model_selection = model_selection
        self.mpFaceDetection = mp.solutions.face_detection
        self.mpDraw = mp.solutions.drawing_utils
        self.faceDection = self.mpFaceDetection.FaceDetection(0.4)

    def createBox(self, img, results):
        if results.detections:
            for id, detection in enumerate(results.detections):
                #mpDraw.draw_detection(img, detection)
                #print(id, detection)
                # print(detection.score)
                # print(detection.location_data.relative_bounding_box)
                bboxc = detection.location_data.relative_bounding_box
                ih, iw, ic = img.shape
                bbox = int(bboxc.xmin * iw), int(bboxc.ymin *
                                                 ih), int(bboxc.width * iw), int(bboxc.height * ih)
                cv2.rectangle(img, bbox, (255, 0, 255), 2)
                cv2.putText(img, f'{int(detection.score[0]*100)}%', (bbox[0], bbox[1] - 25),
                            cv2.FONT_HERSHEY_DUPLEX, 3, (0, 0, 0), 2)
                self.thickAngle(img, bbox)

    def thickAngle(self, img, bbox, l=25, t=20, rt=1):
        x, y, w, h = bbox
        x1, y1 = x+w, y+h
        #cv2.rectangle(img, bbox, (255, 0, 255), rt)
        cv2.line(img, (x, y), (x+l, y), (255, 0, 255), t)
        cv2.line(img, (x, y), (x, y+l), (255, 0, 255), t)
        cv2.line(img, (x1, y), (x1, y+l), (255, 0, 255), t)
        cv2.line(img, (x1, y), (x1-l, y), (255, 0, 255), t)
        cv2.line(img, (x, y1), (x, y1-l), (255, 0, 255), t)
        cv2.line(img, (x, y1), (x+l, y1), (255, 0, 255), t)
        cv2.line(img, (x1, y1), (x1-l, y1), (255, 0, 255), t)
        cv2.line(img, (x1, y1), (x1, y1-l), (255, 0, 255), t)


def main():
    cap = cv2.VideoCapture("videos/6.mp4")
    pTime = 0
    Detect = FaceDetect()
    while True:
        success, img = cap.read()

        # print(img)
        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = Detect.faceDection.process(img)
        # print(results)
        Detect.createBox(img, results)

        cTime = time.time()
        if cTime != pTime:
            fps = 1/(cTime - pTime)
        pTime = cTime
        cv2.putText(img, f'FPS: {int(fps)}', (20, 70),
                    cv2.FONT_HERSHEY_DUPLEX, 3, (0, 200, 100), 2)
        cv2.imshow('Image', img)
        cv2.waitKey(10)


if __name__ == "__main__":
    main()
